* Notes on development of CDL fitting functions

Just notes taken regarding the development an elegant solution to the
implementation of the fitting functions for CDL data.
It's mostly rambling and not very coherent in parts though..

Alternative approach is a creation of the principle functions at
compile time. Then we still need to determine the lines at runtime! We
cannot really get around that, because we need the histogram to base our
starting parameters on.
However: we might be able to use almost the same approach, once at compile time
with dummy values and then at runtime have the =getLines= function
return the same data structures but with values filled.

=FitFuncArgs= is the basis for the function building process. It looks
like this:
#+BEGIN_SRC nim
type
  FitFuncKind = enum
    ffConst, ffPol1, ffPol2, ffGauss, ffExpGauss

  FitFuncArgs = object
    name: string
    case kind: FitFuncKind
    of ffConst:
      c: float
    of ffPol1:
      cp: float
    of ffPol2:
      cpp: float
    of ffExpGauss:
      ea: float
      eb: float
      eN: float
      emu: float
      es: float
    of ffGauss:
      gN: float
      gmu: float
      gs: float
#+END_SRC
where =FitFuncKind= defines the different parts of functions that we
have to take care of. The variant object =FitFuncArgs= is simply a
single term in the total fit function, so that the final function can
always be written as:
\begin{equation}
f(E) = \sum_i p_{\text{FFA}}
\end{equation}
where $p_{\text{FFA}}$ is a single =FitFuncArgs=, i.e. the final
function of energy =E= is just a sum of all function parts.

At the same time =FitFuncArgs= can also be utilized to store the start
parameters of each fit function. There's a small caveat though. If we
reuse the same data structure for function creation at compile time
and start parameters at runtime, a =seq[FitFuncArgs]= is unsafe, since
a CDL fitting function may contain several of the same parts, e.g. two
=ffGauss=. In this case we have to make sure to always keep the same
order for the runtime part as we use for the compile time creation, so
that we don't confuse two peaks (in principle that doesn't really
matter, since the function terms are identical, but when printing the
resulting fit parameters, we need to be able to identify which
parameter is for which function part :) ).

** Creation of functions at compile time

First we need to define the functions at compile time, before we can
continue. The resulting functions need to have the signature:
#+BEGIN_SRC nim
CdlFitFunc = proc(p_ar: seq[float], x: float): float
#+END_SRC
since that is used by =mpfit= and =nlopt=. We additionally define a
type =CdlFit=, which will store the thus generated function:
#+BEGIN_SRC nim
type
  CdlFit = object
    target: TargetKind
    filter: FilterKind
    hv: float
    fit: CdlFitFunc
#+END_SRC

Assuming we have the =CEpic= function, consisting of two gaussians:
#+BEGIN_SRC nim
const cEpicF = @[FitFuncArgs(name: "C-Kalpha", kind: ffGauss),
                 FitFuncArgs(name: "O-Kalpha", kind: ffGauss)]
#+END_SRC
Note, that we either have to define =cEpicF= as a =const= or as a
=compileTime= variable like so:
#+BEGIN_SRC nim
var cEpicF {.compileTime.} = ...
#+END_SRC
so that we can use these objects to define a function at compile time.

The code we had in the file so far looks like the following:
#+BEGIN_SRC nim
template buildFitProc(name: untyped, parts: seq[FitFuncArgs]): untyped =
  var params: seq[float]
  var funcBody: float
  for p in parts:
    case p.kind
    of ffGauss:
      funcBody += p.gN * gauss(x, p.gmu, p.gs)
    of ffExpGauss:
      funcBody += expGauss(@[p.ea, p.eb, p.eN, p.emu, p.es], x)
  proc `name`(p_ar: seq[float], x: float): float =
    result = funcBody
  `name`
#+END_SRC
However, this cannot work. We mix calling a function at runtime with
specific values, e.g. =gauss(x, p.gmu, p.gs)= with the creation of a
procedure at compile time. In this case the biggest problem is the
fact that we try to build the =funcBody= in the template via a loop,
but call the functions already with =x=, which isn't defined yet. We
can rescue the code to an extent by putting the loop into the proc
body like so:
#+BEGIN_SRC nim
template buildFitProc(name: untyped, parts: seq[FitFuncArgs]): untyped =
  var params: seq[float]
  var funcBody: float
  proc `name`(p_ar: seq[float], x: float): float =
    for p in parts:
      case p.kind
      of ffGauss:
        result += p.gN * gauss(x, p.gmu, p.gs)
      of ffExpGauss:
        result += expGauss(@[p.ea, p.eb, p.eN, p.emu, p.es], x)
      else: discard
  `name`
#+END_SRC
Now at least the code can almost compile, but in this way it still
won't due to a stupid bug. If calling the template like:
#+BEGIN_SRC nim
buildFitProc(test, cEpicF)
#+END_SRC
we'd be greeted with
#+BEGIN_SRC sh
Error: expression 'test' is of type 'proc (p_ar: seq[float], x: float): float{.noSideEffect, gcsafe, locks: 0.}' and has to be discarded; for a function call use ()
#+END_SRC
which just tells us that in our code we're defining a function and
then writing =test= in the code. Using =expandMacros= from the
=macros= module, we can see what the template does:
#+BEGIN_SRC nim
expandMacros:
  buildFitProc(test, cEpicF)
#+END_SRC
prints at compilation time the following:
#+BEGIN_SRC nim
var params190155: seq[float]
var funcBody190156: float
proc test(p_ar190157: seq[float]; x190158: float): float =
  for p190159 in items(cEpicF):
    case p190159.kind
    of ffGauss:
      result += p190159.gN * gauss(x190158, p190159.gmu, p190159.gs)
    of ffExpGauss:
      result += expGauss(@[p190159.ea, p190159.eb, p190159.eN, p190159.emu, p190159.es],
                       x190158)
    else:
      discard

test
#+END_SRC
The problem is that the line =`name`= in the template at the end just
writes out the function name (not even as a function call). And the
compiler complains to us that the expression =test= is simply a
function of a certain type and has to be discarded, e.g.
#+BEGIN_SRC nim
discard test
#+END_SRC
would actually be valid, although it wouldn't do anything. The
compiler even tells us we might want to call a function using =()=
instead. Anyways, this is pretty stupid and my original intent was
actually just to make sure that the proc that we just define will
actually be visible in the global scope. But that isn't actually
necessary. :)

The bigger problem with this code is the fact that we're just mixing
in the elements of =cEpicF= that we hand, but don't do anything with
the parameters of the function that we define, namely =p_ar19015= (or
rather =p_ar= for our purposes). So if we were to define these
functions in such a way and try to call them, handing different
=p_ar= wouldn't have any effect at all! We'd just be using the same
parameters all the time, since they'd be hardcoded.

That's why we need to better split up between compile time declaration
of the functions and runtime calling.

So let's reevaluate what we want to actually do.

At compile time we need the =FitFuncArgs= not actually for their
parameters, e.g. =gN, gmu, gs= from =ffGauss= for instance. But rather
we need them to dispatch onto the correct function to call using the
mentioned =p_ar= above! We can use the approach from above by
inserting the for loop into the definition of our procedure. This
still has one "problem" though. It means all functions we define have
to actually perform the loop over the given =parts= (e.g. =cEpicF=) on
each function call. That will have quite a significant performance
impact. Although for our purpose here performance really isn't an
issue at all. It's just not very elegant, because we do not actually
make proper use of the fact that we know at compile time what the
functions are we're calling! 
NOTE: see the [[Unroll the loop]] section below for an update.
The code may look like the following:
#+BEGIN_SRC nim
template buildFitProc(name: untyped, parts: seq[FitFuncArgs]): untyped =
  proc `name`(p_ar: seq[float], x: float): float =
    var i = 0
    for p in parts:
      case p.kind
      of ffGauss:
        result += p_ar[i] * gauss(x, p_ar[i + 1], p_ar[i + 2])
        inc i, 3 # increase by number of consumed parameters
      of ffExpGauss:
        result += expGauss(p_ar[i .. i + 4], x)
        inc i, 5
      else: discard
#+END_SRC
We simply case on each part and add the given term to the result. The
only thing we have to do is to make sure to call the correct
parameters and give them to the corresponding implemented
functions. For that we use the variable =i=, which we increment the
correct number of parameters in each case.

With such a definition we then can define the start parameters again
using =FitFuncArgs= and have a "serialization" procedure, which turns
a =seq[FitFuncArgs]= into a =seq[float]= corresponding to the =p_ar=
argument of the created function. Then, again, the order of the
=FitFuncArgs= is crucial so that we map the correct parameters to the
correct functions! We could make this more safe, but no point in
complicating things even more.

So then now we just define all equivalents for =cEpicF= in the code to
represent all lines, extend =buildFitProc= to account for all kinds
and actually call =buildFitProc= in the code with each
=seq[FitFuncArgs]= defined. I would propose a nomenclature for the
actual functions like 
#+BEGIN_SRC 
<target><filter>Func
#+END_SRC
e.g. =cEpicFunc=, =mnCrFunc= etc.

*** Unroll the loop

As mentioned in the section above, the =buildFitProc= template we
implemented has an ugly property. It doesn't actually use the fact
that we know at compile time what the function to be implemented
actually looks like. Instead it does two things we'd like to
avoid. Let's look at it's expansion using =expandMacros= to understand
what that is exactly:
#+BEGIN_SRC nim
proc cEpicFuncAlt(p_ar1447574: seq[float]; x1447575: float): float =
  var i1447576 = 0
  for p1447577 in items(cEpicF):
    case p1447577.kind
    of ffGauss:
      result = p_ar1447574[i1447576] * gauss(x1447575, p_ar1447574[i1447576 + 1],
          p_ar1447574[i1447576 + 2], false)
      inc i1447576, 3
    of ffExpGauss:
      result = expGauss(p_ar1447574[i1447576 .. i1447576 + 4], x1447575)
      inc i1447576, 5
    else:
      discard
#+END_SRC
First let's pick out line 3 of this code. It accesses the =cEpicF=
constant that we defined globally! First of all accessing a global
(although it's a =const=, which at least makes it safe) is just not
very nice, as it makes the code more complicated and harder to
understand. Secondly, this means that the constants we actually only
create to properly define the functions need to be stored in the
programs binary, although technically they woulnd't even be needed
anymore. 

The second thing we'd like to avoid is the =for= loop itself and the
=case= statement. Again, since we know what =FitFuncKind= =cEpicF=
contains at compile time, performing a =case= on *every single*
function call (which might be called a lot, if the fit isn't
converging quickly) is just wasteful. The branch predictor of a modern
CPU might detect that the =kind= tends to be the same and hence reduce
the performance impact, but relying on that isn't nice. 

So let's find a way to write this code in such a way that we actually
get rid of these two pain points.

First we can slightly refactor the template for better clarity as to
where our implementation needs to be headed. We see that the case
statement may actually be its own procedure:
#+BEGIN_SRC nim
proc handleFitFuncKind(i: var int, p_ar: seq[float], x: float, p: FitFuncArgs): float =
  case p.kind
  of ffGauss:
    result = p_ar[i] * gauss(x, p_ar[i + 1], p_ar[i + 2])
    inc i, 3 # increase by number of consumed parameters
  of ffExpGauss:
    result = expGauss(p_ar[i .. i + 4], x)
    inc i, 5
  else: discard

template buildFitProc(name: untyped, parts: seq[FitFuncArgs]): untyped =
  proc `name`(p_ar: seq[float], x: float): float =
    var i = 0
    for p in parts:
      result += handleFitFuncKind(i, p_ar, x, p)
#+END_SRC
This way we reduce the generated procedure of the template to a
declaration of an index variable =i=, a =for= loop over =parts= and a
call to our =handleFitFuncKind= procedure. Thus, we only have to write
a macro that creates a procedure, which:
1. replaces the =case= statement at run time by a =case= statement at
   compile time
2. remove the =for= loop and replace it by an unrolled version of the
   elements in the sequence.

**** Write the case statement at compile time

First let's figure out how to write the =case= statement at compile
time.

We start with a barebones macros to investigate what =parts= actually
looks like at compile time:
#+BEGIN_SRC nim
macro buildFitFunc(name: untyped, parts: seq[FitFuncArgs]): untyped =
  echo parts.treeRepr
#+END_SRC
The =treeRepr= procedure is a proc that prints the tree representation
of a =NimNode=. The thing to be aware of is firstly that any (even
typed like =parts: seq[FitFuncArgs]= parameter of a macro, will
actually be =NimNodes= within the macro! 
Calling this macro as =buildFitFunc(test, cEpicF)=, we'll just see the
following line echoed at compile time:
#+BEGIN_SRC nim
Sym "cEpicF"
#+END_SRC
This just tells us that the the argument =parts= is just the already
defined symbol =cEpicF=. Well yeah, that's what we wanted. However, in
the macro we're not really interested in the symbol, but rather the
implementation of that symbol. So we can use =getImpl= for that:
#+BEGIN_SRC nim
echo parts.getImpl.treeRepr
#+END_SRC
within the macro, will surprise us with a lot more output at compile
time:
#+BEGIN_SRC nim
Bracket           
  ObjConstr      
    Empty     
    ExprColonExpr 
      Sym "name" 
      StrLit "C-Kalpha"
    ExprColonExpr 
      Sym "kind" 
      IntLit 3
    ExprColonExpr 
      Sym "c"    
      FloatLit 0.0
    ExprColonExpr 
      Sym "cp"   
      FloatLit 0.0
    ExprColonExpr 
      Sym "cpp"  
      FloatLit 0.0
    ExprColonExpr 
      Sym "ea"   
      FloatLit 0.0
    ExprColonExpr 
      Sym "eb"   
      FloatLit 0.0
    ExprColonExpr 
      Sym "eN"
      FloatLit 0.0
    ExprColonExpr
      Sym "emu"                                                         
      FloatLit 0.0                
    ExprColonExpr     
      Sym "es"
      FloatLit 0.0
    ExprColonExpr     
      Sym "gN"
      FloatLit 0.0                                                                                
    ExprColonExpr                                                                            
      Sym "gmu"                                                                                  
      FloatLit 0.0                                                                           
    ExprColonExpr                                                                                 
      Sym "gs"                                                                                          
      FloatLit 0.0                                                                                     
  ObjConstr                                                                                          
    Empty                                                                                     
    ExprColonExpr               
      Sym "name"
      StrLit "O-Kalpha" 
    ExprColonExpr
      Sym "kind"
      IntLit 3
    ExprColonExpr
      Sym "c"
      FloatLit 0.0
    ExprColonExpr
      Sym "cp"
      FloatLit 0.0
    ExprColonExpr
      Sym "cpp"
      FloatLit 0.0
    ExprColonExpr
      Sym "ea"
      FloatLit 0.0
    ExprColonExpr
      Sym "eb"
      FloatLit 0.0
    ExprColonExpr
      Sym "eN"
      FloatLit 0.0
    ExprColonExpr
      Sym "emu"
      FloatLit 0.0
    ExprColonExpr
      Sym "es"
      FloatLit 0.0
    ExprColonExpr
      Sym "gN"
      FloatLit 0.0
    ExprColonExpr
      Sym "gmu"
      FloatLit 0.0
    ExprColonExpr
      Sym "gs"
      FloatLit 0.0
#+END_SRC
While this looks like a *lot* of output, it's actually just what we
wrote in the line in which we declared =cEpicF=:
#+BEGIN_SRC nim
const cEpicF = @[FitFuncArgs(name: "C-Kalpha", kind: ffGauss),
                 FitFuncArgs(name: "O-Kalpha", kind: ffGauss)]
#+END_SRC
except that this time, the =FitFuncArgs= is already expanded to
include all fields of the object with their default values of =0.0=
(for floats). If we throw out the default fields, the output becomes a
little more easy to read:
#+BEGIN_SRC nim
Bracket           
  ObjConstr      
    Empty     
    ExprColonExpr 
      Sym "name" 
      StrLit "C-Kalpha"
    ExprColonExpr 
      Sym "kind" 
      IntLit 3
  ObjConstr                                                                                          
    Empty                                                                                     
    ExprColonExpr               
      Sym "name"
      StrLit "O-Kalpha" 
    ExprColonExpr
      Sym "kind"
      IntLit 3
#+END_SRC
A note about language: anything that is one indented one level more
than the above, is called a =child= node of the =parent= node. Looping
over a =NimNode= means an iterator that yields each =child=
node. =Child= nodes can be accessed from a =parent= using the =[]=
accessor. Of course they are 0 indexed.
So we have a =nnkBracket= node, which resembles the =@[]= in our
declaration of =cEpicFunc= (note: the correct internal name for the
nodes to use them in the macros is actually prefixed by =nnk=, which
stands for =NimNodeKind=). The =nnkObjConstr= node is the name for
each call to =FitFuncArgs=. Since our declaration has two
=FitFuncArgs=, the =nnkBracket= has two child nodes. Aside from the
seemingly random =nnkEmpty= node, the children of the =nnkObjConstr=
simply resemble the implementation of the =FitFuncArgs= object, in the
same order as our implementation lists them:
#+BEGIN_SRC nim
  FitFuncArgs = object
    name: string
    case kind: FitFuncKind
    of ffConst:
      c: float
    of ffPol1:
      cp: float
    of ffPol2:
      cpp: float
    of ffExpGauss:
      ea: float
      eb: float
      eN: float
      emu: float
      es: float
    of ffGauss:
      gN: float
      gmu: float
      gs: float
#+END_SRC
For our purposes then, all we need is the following child node:
#+BEGIN_SRC nim
    ExprColonExpr 
      Sym "kind" 
      IntLit 3
#+END_SRC
because it defines the =kind= of the =FitFuncArgs=. One implementation
detail is visible, i.e. the fact that =enums= are actually just
implemented as simple =sets=, i.e. the possible values are just
integers, by default starting from =0=, counting up (although =enums=
with holes are supported by explicitly assigning integers to the enum
values). 
So we need to extract this node and create a =FitFuncKind= enum value
at compile time. Note: an =enum= *value* and not a =NimNode=, that
contains an =enum= value! Otherwise we can't create a =case= statement
that runs at compile time.
Let's loop over the =parts= nodes at compile time and extract the node
mentioned above. Within the =macro= we have defined, add:
#+BEGIN_SRC nim
  for p in parts.getImpl:
    # each =p= is now each child of `nnkBracket`, i.e. each `nnkObjConstr`
    # using `[]` we can then access the children of `p` again
    let kindNode = p[2]
#+END_SRC
=kindNode= represents the node shown in the previous code snippet
however, we actually need the =int= value contained in the node to
create an enum value: 
#+BEGIN_SRC nim
let enumVal = kindNode[1]
#+END_SRC
But this again is only the =IntLit 3= node from above! We actually
need the real integer value stored. This can be done using the
=intVal= proc:
#+BEGIN_SRC nim
let enumVal = kindNode[1].intVal
#+END_SRC
Now =enumVal= is an actual integer, storing the number 3. We can now
use this value to construct a =FitFuncKind= value of the correct kind:
#+BEGIN_SRC nim
let enumVal = FitFuncKind(kindNode[1].intVal)
#+END_SRC
by just using the constructor for =FitFuncKind= with the argument of
the integer value.

With this we can now actually write:
#+BEGIN_SRC nim
case enumVal
of ffGauss:
  # do something
of ffExpGauss:
  # do something else
else: discard
#+END_SRC
The actual content of each case has to be different than what it was
in the =template= case above though, because we need not return
numerical values, but rather the code that is required! Fortunately,
using a handy macro =quote= this is almost the same as writing the
runtime code. 

As a short reminder, the code that is required is something like
(example the =ffGauss= case):
#+BEGIN_SRC nim
result += p_ar[i] * gauss(x, p[i + 1], p[i + 2])
inc i, 3
#+END_SRC
within the case. What our job now is, is to create the =NimNodes= that
are contained in this snippet and return a =nnkStmtList=, containing
these expressions with the nodes inserted. Assuming we have a node
that describes. We will write a compile time =proc= that will be
called by the macro we define above, that does this. As the arguments
we will give the nodes that need to show up in the code we must
generate. A compile time proc only takes =NimNode= parameters and
return types! It may look like the following (where pFitNode is still
the raw =p= node we had above in the =for= loop):
#+BEGIN_SRC nim
proc genFitFuncImpl(resultNode, idx, paramsNode, xNode, pFitNode: NimNode): NimNode =
  expectKind(pFitNode, nnkObjConstr)
  let fKind = FitFuncKind(pFitNode[2][1].intVal)
  case fKind
  of ffGauss:
    result = quote do:
      `resultNode` += `paramsNode`[`idx`] * gauss(`xNode`,
                                                  `paramsNode`[`idx` + 1],
                                                  `paramsNode`[`idx` + 2])
      inc `idx`, 3 # increase by number of consumed parameters
  of ffExpGauss:
    result = quote do:
      result += expGauss(`paramsNode`[`idx` .. `idx` + 4], `xNode`)
      inc `idx`, 5
  else: discard
#+END_SRC
First we use =expectKind= on the =pFitNode= as a sanity check to make
sure that =pFitNode= is actuall an =nnkObjConstr= node. Then we create
what we called =enumVal= above as =fKind=, followed by the =case=
statement. As mentioned above, using the =quote= macro, we almost
write the exact normal code, except we put a bunch of things into =``=
markers. What this means is "replace the identifier given by the value
of the =NimNode= stored within the identifier". Anything that is not
in =``= will be inserted as is into the code, after potential name
mangling (i.e. turning =x= into =x154932=). =gauss= and =expGauss= do
not have to be unquoted, because they refer to symbols known in the
calling scope.

Remains the question how we need to define the =NimNodes= given as
parameters to the =genFitFuncImpl= proc. For the purposes here, all we
need are =NimNodes= containing Nim identifiers. We can construct such
identifiers using the =ident= proc as:
#+BEGIN_SRC nim
let resultNode = ident"result"
#+END_SRC
which just contains a =nnkIdent= with value ="result"= (seen by
calling =echo resultNode.treeRepr=).

With this we're almost done actually. We just have to define all these
identifiers, construct the =proc body= and the parameters and return
type of the proc we want to create. The latter things are easy. 

The identifiers are defined as:
#+BEGIN_SRC nim
  let
    idx = ident"i"
    paramsNode = ident"p_ar"
    xNode = ident"x"
    resultNode = ident"result"
#+END_SRC
The =proc= return type also simply as:
#+BEGIN_SRC nim
  let retType = ident"float"
#+END_SRC
The parameters are a little more unintuitive, because the typical
#+BEGIN_SRC nim
params: seq[float]
#+END_SRC
is represented by an =nnkIdentDefs= node. =seq[float]= in addition can
not just be written as =ident"seq[float]"=, but actually needs to be
represented as an =nnkBracketExpr=:
#+BEGIN_SRC nim
nnkBracketExpr.newTree(ident"seq", ident"float")
#+END_SRC
The =newTree= proc produces a tree with an arbitrary number of
branches (read as child nodes) of the type =nnkBracketExpr= in this
case. 

Note: if in doubt about how something is represented within Nim
macros, either take a look at the =macros= module documentation:
https://nim-lang.github.io/Nim/macros.html#statements-procedure-declaration
or more conveniently by using the =dumpAstGen= macro, like so:
#+BEGIN_SRC nim
dumpAstGen:
  var x: seq[float]
#+END_SRC
which will print the AST required to produce this code (without the
=newTree= calls however!).

Now we can define the parameters of the =proc= as:
#+BEGIN_SRC nim
let 
  retParNode = nnkIdentDefs.newTree(paramsNode,
                                    nnkBracketExpr.newTree(
                                      ident"seq",
                                      ident"float"),
                                    newEmptyNode())
  retXNode = nnkIdentDefs.newTree(xNode,
                                  ident"float",
                                  newEmptyNode())
#+END_SRC
where we use the =ident= nodes created above.

We're almost done. The =proc= we want to write needs the =i= variable
as a counter for the =p_ar= argument. So we start by creating the
=proc= body and declaring =i=:
#+BEGIN_SRC nim
  # create a node to hold the procedure body
  var procBody = newStmtList()
  # declare the index variable we use
  procBody.add quote do:
    var `idx` = 0
#+END_SRC
Then we can make use of our =genFitFuncImpl= compile time proc to
append to this =nnkStmtList=:
#+BEGIN_SRC nim
  for p in parts.getImpl:
    # add the lines for the function calls
    procBody.add genFitFuncImpl(resultNode, idx, paramsNode, xNode, p)
#+END_SRC

Now we just have to actually put these parts together and assign it to
the =result= variable. We use the convenience =newProc= procedure,
which simplifies the creation of a =proc= a little bit:
#+BEGIN_SRC nim
  # now define the result variable as a new proc
  result = newProc(name = name,
                   params = [retType, retParNode, retXNode],
                   body = procBody,
                   procType = nnkFuncDef)
#+END_SRC
The =params= argument of the =newProc= helper has to be an array,
which contains the return type of the proc first (if there's no
return type, it has to be =newEmptyNode()=), followed by the
=nnkIdentDefs= we defined. In addition we change the =procType= to be
=nnkFuncDef= so that we actually create a =func= instead of a =proc=.

To see that we create the correct code, we can =echo= the =result=
via =repr=:
#+BEGIN_SRC nim
echo result.repr
#+END_SRC

Now let's put all these snippets together and call it in the code:
#+BEGIN_SRC nim
proc genFitFuncImpl(resultNode, idx, paramsNode, xNode, pFitNode: NimNode): NimNode =
  ## the compilet time procedure that creates the implementation lines for
  ## the <target><Filter>Funcs that we create, which calls the correct functions,
  ## e.g.
  ##   result += p_ar[i] * gauss(x, p[i + 1], p[i + 2])
  ##   inc i, 3
  expectKind(pFitNode, nnkObjConstr)
  let fkind = FitFuncKind(pFitNode[2][1].intVal)
  case fKind
  of ffGauss:
    result = quote do:
      `resultNode` += `paramsNode`[`idx`] * gauss(`xNode`,
                                                  `paramsNode`[`idx` + 1],
                                                  `paramsNode`[`idx` + 2])
      inc `idx`, 3 # increase by number of consumed parameters
  of ffExpGauss:
    result = quote do:
      result += expGauss(`paramsNode`[`idx` .. `idx` + 4], `xNode`)
      inc `idx`, 5
  else: discard

macro buildFitFunc(name: untyped, parts: seq[FitFuncArgs]): untyped =
  ## builds a CDL fit function based on the function described by
  ## the `seq[FitFuncArgs]` at compile time. Using the `FitFuncKind` of
  ## each part, it'll write the needed implementation lines for the
  ## call to the correct functions, e.g. `gauss`, `expGauss` etc.
  # define the variables needed in the implementation function and
  # for the parameters
  let
    idx = ident"i"
    paramsNode = ident"p_ar"
    xNode = ident"x"
    resultNode = ident"result"
  # define parameters and return type of the proc we create
  let
    retType = ident"float"
    retParNode = nnkIdentDefs.newTree(paramsNode,
                                      nnkBracketExpr.newTree(
                                        ident"seq",
                                        ident"float"),
                                      newEmptyNode())
    retXNode = nnkIdentDefs.newTree(xNode,
                                    ident"float",
                                    newEmptyNode())
  # create a node to hold the procedure body
  var procBody = newStmtList()
  # declare the index variable we use
  procBody.add quote do:
    var `idx` = 0

  for p in parts.getImpl:
    # add the lines for the function calls
    procBody.add genFitFuncImpl(resultNode, idx, paramsNode, xNode, p)

  # now define the result variable as a new proc
  result = newProc(name = name,
                   params = [retType, retParNode, retXNode],
                   body = procBody,
                   procType = nnkFuncDef)
  echo result.repr

buildFitFunc(cEpicFunc, cEpicF)
#+END_SRC

Upon compilation we're shown the following:
#+BEGIN_SRC nim
func cEpicFunc(p_ar: seq[float]; x: float): float =
  var i = 0       
  result += p_ar[i] * gauss(x, p_ar[i + 1], p_ar[i + 2], false)
  inc i, 3    
  result += p_ar[i] * gauss(x, p_ar[i + 1], p_ar[i + 2], false)
  inc i, 3 
#+END_SRC
Which is just what we wanted! A specific, simple =func=, that *only*
contains the code required for the =cEpicF= we gave to the macro. No
more overheads and no more =const cEpicF= that need to live after
compilation (which means we can actually replace the =const cEpicF=
lines in the code by =var cEpicF {.compileTime.} = ...=, so these
variables actually do not show up in the resulting binary!

** Calling functions at runtime

With the definition of procedures in place, we can now revisit the
=getLines= function that's already defined in the code and implement
the serialization proc that turns this into a simple =seq[float]= to
use for the actual fitting.

=getLines= at the moment without comments looks like and only a
single case used:
#+BEGIN_SRC nim
func getLines(hist, binning: seq[float], tfKind: TargetFilterKind): seq[FitFuncArgs] =
  let muIdx = argmax(hist)
  case tfKind
  of tfCEpic:
    result.add FitFuncArgs(name: "C-Kalpha",
                           kind: ffGauss,
                           gmu: binning[muIdx],
                           gN: hist[muIdx],
                           gs: hist[muIdx] / 10.0)
    result.add FitFuncArgs(name: "O-Kalpha",
                           kind: ffGauss,
                           gmu: binning[muIdx],
                           gN: hist[muIdx],
                           gs: hist[muIdx] / 10.0)
  else: discard
#+END_SRC

We will call this function after reading the =hits= dataset in the
corresponding H5 file from a CDL run (and having done some cleaning)
and calculated the histogram of that with a given binning, similar to
what we do to fit the Fe spectrum in =calibration.nim=:
#+BEGIN_SRC nim
proc fitFeSpectrum*(data: seq[int]): (seq[float], seq[int], seq[float]) =
  const binSize = 3.0
  let low = -0.5
  var high = max(data).float + 0.5
  let nbins = (ceil((high - low) / binSize)).int
  # using correct nBins, determine actual high
  high = low + binSize * nbins.float
  let bin_edges = linspace(low, high, nbins + 1)
  let hist = data.histogram(bins = nbins + 1, range = (low, high))

  result[2] = fitFeSpectrumImpl(hist.mapIt(it.float), bin_edges[0 .. ^1])
  result[0] = bin_edges[0 .. ^1]
  result[1] = hist
#+END_SRC
where I removed some comments (we should probably create a function
that receives =data= and returns only =hist= and the correct
=bin_edges= given a certain number of bins or bin size. I.e. a wrapper
around histogram that also returns the bin edges.

Assuming we now have =hist= and =bin_edges= as variables in our code,
we can continue:
#+BEGIN_SRC nim
let lines = getLines(hist, bin_edges, tfCEpic)
let params = lines.serialize
#+END_SRC
So all we have left to do is implement the =serialize= proc. This
needs to closely follow our implementation of the case statement
within the =buildFitProc= so that the indices actually match.

Let's do this:
#+BEGIN_SRC nim
proc serialize(parts: seq[FitFuncArgs]): seq[float] =
  for p in parts:
    case p.kind
    of ffGauss:
      result.add @[p.gN, p.gmu, p.gs]
    of ffExpGauss:
      result.add @[p.ea, p.eb, p.eN, p.emu, p.es]
    else: discard
#+END_SRC
etc. the parameters should be in the order, in which they have to be
given to the actual implementation functions! 

Once we have serialized the parameters (and potentially dealt with
bounds for the parameters; but this can wait, first see whether the
fits work in principle or not), we can just call =mpfit= or =nlopt= to
perform the fitting for us (again, see =calibration.nim= for
examples).

** Make use of =CdlFit=

In the code above we completely ignore the =CdlFit= object so far. For
the actual implementation it's not actually needed, but in comes in
handy, when we run over the run list to automatically deal with the
whole code above in a general manner, without having to manually
define the arguments to functions like =getLines= etc.

We need to be clear on the structure of the code.
At compile time:
- at compile time we define the constants like =cEpicF=, which define
  what the CDL fitting functions /look like/ and then use each of
  these to create the corresponding fitting function. So below the
  definition of the =buildFitProc= template, we add 
  #+BEGIN_SRC nim
  cEpicF = @[...] # see above
  buildFitProc(cEpicFunc, cEpicF) # see naming nomenclature above
  #+END_SRC
  (NOTE: regarding the naming nomenclature, we could easily write a
  macro that creates these procedure names for us, either based on the
  actual =TargetFilterKind= or just the name of the variable of
  e.g. =cEpicF= (the former would be preferred, but depending on how
  the code is written, this may not be available at compile time
  without hardcoding the targets / filters or writing a macro that
  iterates over the =TargetFilterKind= enum. Neither worth the
  complication here).
At run time:
- perform the parsing of the CDL run list as already done in the code
- read the =hits= data of the correct run in the file
- making use of the =CdlRun= object, define the =CdlFit= object (Note:
  there's one thing left to do here, we'll handle below)
- using the hits data and the =CdlRun= perform the =getLines= call and
  perform the fit

The thing missing from this list is how to assign the correct
=CdlFitFunc= to the =CdlFit= object. The =CdlRun= object contains the
=target= and =filter= fields. Using the naming scheme mentioned above
that is given as the argument to =buildFitProc=, we can create the
identifier required (in contrast to the above note, creating the
correct identifier - read as proc name - is easy here, because we
already know which target and filter we look at).

NOTE: In hindsight the above is not exactly the case. At least not if
compared to the straight and simple manual coding of the created
proc. Since it's only a few lines of code it's questionable whether
the macro approach is actually worth it. Anyways, I'll let it in here.

So if we have some =CdlRun= object named =cdlRun=, generating the
=CdlFit= may look like shown below. What we aim for is just a proc
that takes =target= and =filter=, creates a string from the
combination, and then a =case= statement that checks for all string
values that may show up as target / filter pairs and return the
appropriate fit function. 
An implementation based on the =TargetFilterKind= enum using a macro:
#+BEGIN_SRC nim
type
  # the target filter kind definitions
  TargetFilterKind = enum
    tfCuNi = "Cu-Ni"
    tfMnCr = "Mn-Cr"
    tfTiTi = "Ti-Ti"
    tfAgAg = "Ag-Ag"
    tfAlAl = "Al-Al"
    tfCuEpic = "Cu-Epic"
    tfCEpic =  "C-Epic"    

macro genTfToFilterProc(): untyped =
  # get the enum of the `TargetFilterKind`
  # The AST looks like this:
  # EnumTy
  #   Empty
  #   Sym "tfTiTi"
  #   Sym "tfCEpic"
  #   ...
  let tfkind = getType(TargetFilterKind)
  # first generate the string combinations that make up the
  # prefix of the function names
  var funcNames: seq[string]
  for x in tfKind:
    # check if we look at the `Empty` element shown above
    if x.kind != nnkEmpty:
      let xStr = $(x.getImpl)
      funcNames.add xStr.toLowerAscii.replace("-", "") & "Func"
  # define all identifiers we need in our proc, i.e. all variable 
  # names that will end up in the function
  let 
    pname = ident"getCdlFitFunc"
    arg1 = ident"target"
    argt1 = ident"TargetKind"
    arg2 = ident"filter"
    argt2 = ident"FilterKind"
    cdf = ident"CdlFitFunc"
    tfNameNode = ident"n"
    resIdent = ident"result"
 
  # now we build the case statement that will go into the procedure
  var  caseStmt = nnkCaseStmt.newTree(tfNameNode)
  for n in funcNames:
    let retId = ident(n)
    let retval = quote do:
      `resIdent` = `retId`
    caseStmt.add nnkOfBranch.newTree(newLit n, retval)
  # finally assign the result of the macro to a quote block, that
  # creates the simple proc
  result = quote do:
    proc `pname`(`arg1`: `argt1`, `arg2`: `argt2`): `cdf` =
      let `tfNameNode` = ($`arg1`).toLowerAscii & $`arg2` & "Func"
      `caseStmt`
  echo result.repr
#+END_SRC
The created proc is just the following:
#+BEGIN_SRC nim
proc getCdlFitFunc(target: TargetKind; filter: FilterKind): CdlFitFunc =
  let n = ($target).toLowerAscii &
      $filter & "Func"
  case n
  of "titiFunc":
    result = titiFunc
  of "cepicFunc":
    result = cepicFunc
  ...
#+END_SRC
As mentioned in the note above, although in total it's 7 cases writing
it manually is probably a better idea anyways. For a lot more cases
this would soon start to be very handy, since the lines of code
wouldn't change at all.

In any case, with this implemented, we have all pieces available to
us to put everything together. We just create a =CdlFit= object based
on the common fields with the =CdlRun= object that we have, use the
just created =getCdlFitFunc= to assign the field in the object and we
can go to [[Calling functions at runtime]] in our code.

NOTE: the above actually makes the definition of the =getCdlFits=
procedure in the current file obsolete.
